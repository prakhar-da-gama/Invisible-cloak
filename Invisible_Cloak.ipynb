{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Invisible Cloak.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emgnUB0HIea4",
        "outputId": "52846936-1db1-48d4-a8a2-665eee35de80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invisible Cloak\n",
        "This project is based on invisible cloak used in Harry Potter series. This was possible due to Image Processing Technique called Colour Detection and Segmentation applied using  simple computer vision techniques in OpenCV.\n",
        "\n",
        "Tools Used\n",
        "\n",
        "I have made this project using Python3, NumPy and OpenCV."
      ],
      "metadata": {
        "id": "S-Y6fzM-IfeX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArJKUaG8IBCM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "8c7a4bef-49dc-4fda-8878-b09deba3beeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-bf9fd7020098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INVISIBLE MAN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# replace the red pixels ( or undesired area ) with\n",
        "# background pixels to generate the invisibility feature.\n",
        "\n",
        "## 1. Hue: This channel encodes color information. Hue can be\n",
        "# thought of an angle where 0 degree corresponds to the red color,\n",
        "# 120 degrees corresponds to the green color, and 240 degrees\n",
        "# corresponds to the blue color.\n",
        "\n",
        "## 2. Saturation: This channel encodes the intensity/purity of color.\n",
        "# For example, pink is less saturated than red.\n",
        "\n",
        "## 3. Value: This channel encodes the brightness of color.\n",
        "# Shading and gloss components of an image appear in this\n",
        "# channel reading the videocapture video\n",
        "\n",
        "# in order to check the cv2 version\n",
        "print(cv2.__version__)\n",
        "\n",
        "# taking video.mp4 as input.\n",
        "# Make your path according to your needs\n",
        "capture_video = cv2.VideoCapture(\"/content/drive/MyDrive/video.mp4\")\n",
        "#/content/drive/MyDrive/video.mp4\n",
        "##########\n",
        "\t\n",
        "# give the camera to warm up\n",
        "time.sleep(1)\n",
        "count = 0\n",
        "background = 0\n",
        "\n",
        "# capturing the background in range of 60\n",
        "# you should have video that have some seconds\n",
        "# dedicated to background frame so that it\n",
        "# could easily save the background image\n",
        "for i in range(60):\n",
        "\treturn_val, background = capture_video.read()\n",
        "  \n",
        "\tif return_val == False :\n",
        "\t\tcontinue\n",
        "\n",
        "background = np.flip(background, axis = 1) # flipping of the frame\n",
        "\n",
        "# we are reading from video\n",
        "while (capture_video.isOpened()):\n",
        "\treturn_val, img = capture_video.read()\n",
        "\tif not return_val :\n",
        "\t\tbreak\n",
        "\tcount = count + 1\n",
        "\timg = np.flip(img, axis = 1)\n",
        "\n",
        "\t# convert the image - BGR to HSV\n",
        "\t# as we focused on detection of red color\n",
        "\n",
        "\t# converting BGR to HSV for better\n",
        "\t# detection or you can convert it to gray\n",
        "\thsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "\t#-------------------------------------BLOCK----------------------------#\n",
        "\t# ranges should be carefully chosen\n",
        "\t# setting the lower and upper range for mask1\n",
        "\tlower_red = np.array([100, 40, 40])\t\n",
        "\tupper_red = np.array([100, 255, 255])\n",
        "\tmask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\t# setting the lower and upper range for mask2\n",
        "\tlower_red = np.array([155, 40, 40])\n",
        "\tupper_red = np.array([180, 255, 255])\n",
        "\tmask2 = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\t#----------------------------------------------------------------------#\n",
        "\n",
        "\t# the above block of code could be replaced with\n",
        "\t# some other code depending upon the color of your cloth\n",
        "\tmask1 = mask1 + mask2\n",
        "\n",
        "\t# Refining the mask corresponding to the detected red color\n",
        "\tmask1 = cv2.morphologyEx(mask1, cv2.MORPH_OPEN, np.ones((3, 3),\n",
        "\t\t\t\t\t\t\t\t\t\tnp.uint8), iterations = 2)\n",
        "\tmask1 = cv2.dilate(mask1, np.ones((3, 3), np.uint8), iterations = 1)\n",
        "\tmask2 = cv2.bitwise_not(mask1)\n",
        "\n",
        "\t# Generating the final output\n",
        "\tres1 = cv2.bitwise_and(background, background, mask = mask1)\n",
        "\tres2 = cv2.bitwise_and(img, img, mask = mask2)\n",
        "\tfinal_output = cv2.addWeighted(res1, 1, res2, 1, 0)\n",
        "\n",
        "\tcv2.imshow(\"INVISIBLE MAN\", final_output)\n",
        "\tk = cv2.waitKey(10)\n",
        "\tif k == 27:\n",
        "\t\tbreak\n"
      ]
    }
  ]
}